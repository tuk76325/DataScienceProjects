{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3a32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "age           0\n",
      "sex           0\n",
      "bmi           0\n",
      "children      0\n",
      "smoker        0\n",
      "region        0\n",
      "charges       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('preprocessedInsuranceDoodnauth.csv')\n",
    "\n",
    "print(df.isnull().sum()) #data was processed in the last lab (lab 02)\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "insurance_df['sex'] = labelencoder.fit_transform(insurance_df['sex'])\n",
    "insurance_df['smoker'] = labelencoder.fit_transform(insurance_df['smoker'])\n",
    "insurance_df['region'] = labelencoder.fit_transform(insurance_df['region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59178197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 7)\n",
      "(268, 7)\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Split the preprocessed dataset into training set and testing set\n",
    "\n",
    "# Use 80% of samples as the training set and 20% of samples as the testing set\n",
    "\n",
    "insurance_fea = df.drop('charges', axis=1).values\n",
    "insurance_price = df['charges'].values\n",
    "insurance_price = insurance_price / np.max(insurance_price)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(insurance_fea,\n",
    "                                                 insurance_price,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e8264b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias is 0.19512367061019303\n",
      "coefficients are [ 3.21129571e-03  5.78315012e-02 -7.48113826e-05  3.24501224e-02\n",
      "  8.11978026e-03  1.52472215e-01 -4.80667539e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06708954863253438\n",
      "MSE is: 0.009488377087984463\n",
      "RMSE is: 0.09740830091929775\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Train the linear regression model\n",
    "\n",
    "# Here, we use the training set to learn the model parameter\n",
    "\n",
    "# Then, we compute MAE, MSE, and RMSE to see how well the learned model fit the training set.\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('bias is ' + str(lr.intercept_))\n",
    "print('coefficients are ' + str(lr.coef_))\n",
    "\n",
    "y_train_pred = lr.predict(X_train) #model parameter w\n",
    "\n",
    "mae = mean_absolute_error(y_train_pred,y_train)\n",
    "mse = mean_squared_error(y_train_pred,y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18146bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for testing set:\n",
      "MAE is: 0.06706040782790473\n",
      "MSE is: 0.008622876428942352\n",
      "RMSE is: 0.09285944447896699\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.4 Evaluate the linear regression model\n",
    "\n",
    "# After obtaining the model parameter, the linear regression model is determined. \n",
    "# Then, we need to evaluate this model to see how well this model generaizes on the testing set.\n",
    "\n",
    "#4. evaluate the model\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['Price 1', 'Price 2', 'Price 3', 'Price 4', 'Price 5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c3883ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "lambda = 1\n",
      "bias is 0.19512367061019303\n",
      "coefficients  is [ 3.20957661e-03  5.77729173e-02 -6.43622567e-05  3.24246348e-02\n",
      "  8.11765351e-03  1.52326136e-01 -4.79823057e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06708691834902256\n",
      "MSE is: 0.008624621222064928\n",
      "RMSE is: 0.09286883881079233\n",
      "-----------------------------------------------------\n",
      "lambda = 2\n",
      "bias is 0.19512367061019303\n",
      "coefficients  is [ 3.20785815e-03  5.77144531e-02 -5.39523588e-05  3.23991857e-02\n",
      "  8.11552011e-03  1.52180338e-01 -4.78980797e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06711337236924136\n",
      "MSE is: 0.00862641578478291\n",
      "RMSE is: 0.09287850012130315\n",
      "-----------------------------------------------------\n",
      "lambda = 0.5\n",
      "bias is 0.19512367061019303\n",
      "coefficients  is [ 3.21043608e-03  5.78021942e-02 -6.95819057e-05  3.24373738e-02\n",
      "  8.11871772e-03  1.52399140e-01 -4.80245019e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06707367016230678\n",
      "MSE is: 0.008623742585609268\n",
      "RMSE is: 0.09286410816676843\n",
      "-----------------------------------------------------\n",
      "lambda = 3\n",
      "bias is 0.19512367061019303\n",
      "coefficients  is [ 3.20614032e-03  5.76561085e-02 -4.35815227e-05  3.23737752e-02\n",
      "  8.11338012e-03  1.52034821e-01 -4.78140752e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06713977006778002\n",
      "MSE is: 0.008628259819080525\n",
      "RMSE is: 0.09288842672303436\n",
      "-----------------------------------------------------\n",
      "lambda = 0.1\n",
      "bias is 0.19512367061019303\n",
      "coefficients  is [ 3.21112377e-03  5.78256374e-02 -7.37647000e-05  3.24475719e-02\n",
      "  8.11956788e-03  1.52457595e-01 -4.80582990e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06706306142768033\n",
      "MSE is: 0.008623048660092869\n",
      "RMSE is: 0.09286037184985245\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Use the ridge regression model to do prediction\n",
    "\n",
    "# 1.5.1 Compare its performance on the testing set with that of the standard linear regression model\n",
    "# train the ridge model (lambda = 1)\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "print('lambda = 1')\n",
    "clf = Ridge(alpha = 1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"bias is \"+str(clf.intercept_))\n",
    "print(\"coefficients  is \"+str(clf.coef_))\n",
    "\n",
    "new_y_test_pred = clf.predict(X_test) #predict with testing set\n",
    "\n",
    "mae = mean_absolute_error(new_y_test_pred,y_test)\n",
    "mse = mean_squared_error(new_y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "\n",
    "print('lambda = 2')\n",
    "\n",
    "# 1.5.2 Use different lambdas to see how it affects the performance of the ridge regression model on the testing set\n",
    "\n",
    "# lambda = 2\n",
    "\n",
    "clf = Ridge(alpha = 2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"bias is \"+str(clf.intercept_))\n",
    "print(\"coefficients  is \"+str(clf.coef_))\n",
    "\n",
    "new_y_test_pred = clf.predict(X_test) #predict with testing set\n",
    "\n",
    "mae = mean_absolute_error(new_y_test_pred,y_test)\n",
    "mse = mean_squared_error(new_y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "print('lambda = 0.5')\n",
    "\n",
    "# lambda = 0.5\n",
    "\n",
    "clf = Ridge(alpha = 0.5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"bias is \"+str(clf.intercept_))\n",
    "print(\"coefficients  is \"+str(clf.coef_))\n",
    "\n",
    "new_y_test_pred = clf.predict(X_test) #predict with testing set\n",
    "\n",
    "mae = mean_absolute_error(new_y_test_pred,y_test)\n",
    "mse = mean_squared_error(new_y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "print('lambda = 3')\n",
    "\n",
    "# lambda = 3\n",
    "\n",
    "clf = Ridge(alpha = 3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"bias is \"+str(clf.intercept_))\n",
    "print(\"coefficients  is \"+str(clf.coef_))\n",
    "\n",
    "new_y_test_pred = clf.predict(X_test) #predict with testing set\n",
    "\n",
    "mae = mean_absolute_error(new_y_test_pred,y_test)\n",
    "mse = mean_squared_error(new_y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "print('-----------------------------------------------------')\n",
    "print('lambda = 0.1')\n",
    "\n",
    "# lambda = 0.1\n",
    "\n",
    "clf = Ridge(alpha = 0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"bias is \"+str(clf.intercept_))\n",
    "print(\"coefficients  is \"+str(clf.coef_))\n",
    "\n",
    "new_y_test_pred = clf.predict(X_test) #predict with testing set\n",
    "\n",
    "mae = mean_absolute_error(new_y_test_pred,y_test)\n",
    "mse = mean_squared_error(new_y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12772ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By utilizing the Ridge regression model (with lambdas = 1, 2, 0.5, 3, and 0.1), it was seen that the linear regression model\n",
    "# proved slightly more accurate compared to the Ridge regression. With that being said, the values were still extremely close.\n",
    "# Within the Ridge regression, as lambda decreased, the MAE, MSE, and RMSE, also decreased.\n",
    "# This makes sense has the Ridge model only adds a penalty parameter (w^2) to minimize the model complexity and thus, overfitting. \n",
    "# This was seen in the MAE, MSE, and RMSE, where the performance for the linear regression model denoted a lower number on the\n",
    "# order of the millionths (1 x 10^-6) for the MAE and MSE, and on the hundred-thousandths (1 x 10^-5) for the RMSE.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
